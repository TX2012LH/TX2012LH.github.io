
<html>
<head>
    <meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
    <title>Hao Luo</title>
    <meta content="Hao Luo, tx2012lh.github.io" name="keywords" />
    <style media="screen" type="text/css">html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
        border: 0pt none;
        font-family: inherit;
        font-size: 100%;
        font-style: inherit;
        font-weight: inherit;
        margin: 0pt;
        outline-color: invert;
        outline-style: none;
        outline-width: 0pt;
        padding: 0pt;
        vertical-align: baseline;
    }
    a {
        color: #1772d0;
        text-decoration:none;
    }
    a:focus, a:hover {
        color: #f09228;
        text-decoration:none;
    }
    a.paper {
        font-weight: bold;
        font-size: 12pt;
    }
    b.paper {
        font-weight: bold;
        font-size: 12pt;
    }
    * {
        margin: 0pt;
        padding: 0pt;
    }
    body {
        position: relative;
        margin: 3em auto 2em auto;
        width: 800px;
        font-family: Lato, Verdana, Helvetica, sans-serif;
        font-size: 12px;
        background: #eee;
        font-weight: 500;
    }
    h2 {
        font-family: Lato, Verdana, Helvetica, sans-serif;
        font-size: 12pt;
        font-weight: 600;
    }
    h3 {
        font-family: Lato, Verdana, Helvetica, sans-serif;
        font-size: 12px;
        font-weight: 600;
    }
    strong {
        font-family: Lato, Verdana, Helvetica, sans-serif;
        font-size: 12px;
        font-weight:bold;
    }
    ul {
        list-style: circle;
    }
    img {
        border: none;
    }
    li {
        padding-bottom: 0.5em;
        margin-left: 1.4em;
    }
    alert {
        font-family: Lato, Verdana, Helvetica, sans-serif;
        font-size: 13px;
        font-weight: bold;
        color: #FF0000;
    }
    em, i {
        font-style:italic;
    }
    div.section {
        clear: both;
        margin-bottom: 1.5em;
        background: #eee;
    }
    div.spanner {
        clear: both;
    }
    div.paper {
        clear: both;
        margin-top: 0.5em;
        margin-bottom: 1em;
        border: 1px solid #ddd;
        background: #fff;
        padding: 1em 1em 1em 1em;
    }
    div.paper div {
        padding-left: 230px;
    }
    img.paper {
        margin-bottom: 0.5em;
        float: left;
        width: 200px;
    }
    span.blurb {
        font-style:italic;
        display:block;
        margin-top:0.75em;
        margin-bottom:0.5em;
    }
    pre, code {
        font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
        margin: 1em 0;
        padding: 0;
    }
    div.paper pre {
        font-size: 0.9em;
    }
    </style>

    <link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css" /><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
</head>
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
</script>
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)}, i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-66888300-1', 'auto');
    ga('send', 'pageview');
</script>

<body>
    <div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 140px;">
        <div style="margin: 0 auto; width: 100%;">
            <img title="Hao Luo" style="float: left; padding-left: .01em; height: 140px;" src="material/hao_luo.jpg" />
            <div style="padding-left: 18.5em; vertical-align: top; height: 120px;"><span style="line-height: 150%; font-size: 18pt;">Hao Luo (罗 浩)</span><br/><br/>
                <span><strong>Email  </strong>: luohao4898 [AT] hotmail [DOT] com</span><br/><br/>
                <span><strong>Resume  </strong>: <a href='material/haoluo.pdf'>haoluo_cv</a></span><br/><br/>
                <span><strong>Bio </strong>: <s> I'm now a master student in <a href="http://www.hust.edu.cn/">HUST</a>. I mainly focus on the task of image/video object detection, video editing.</s></span>
                
            </div>
        </div>
    </div>
    <!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->

    <div style="clear: both;">
        <div class="section">
            <h2>Education</h2>
            <div class="paper">
                Nov. 2016 - Jul. 2019, <a href="http://www.hust.edu.cn/">HUST</a>(Huazhong University of Science and Technology), Wuhan.
                <br> Degree/Major: Master (<b>postgraduate recommendation</b>) of Information and Communication Engineering.
                <br> Supervised by: <a href="http://www.xinggangw.info/">Assoc. Prof. XingGang Wang</a>
                <br> Topic: Deep learning, Image/Video object detection, Video editing.
                <br> Thesis: Efficient video object detection based on CNN.
                <br/><br/>
                Sep. 2012 - Jul. 2016, <a href="http://www.hust.edu.cn/">HUST</a>, Wuhan.
                <br> Degree/Major: Bachelor of Electronic information and communications engineering.
                <br> Thesis: Convolutional neural network based object part detection.
            </div>
        </div>
    </div>
    <div style="clear: both;">
        <div class="section">
            <h2>Work Experience</h2>
            <div class="paper">
                Jun. 2019 - Now, <b>Algorithm Engineer</b>, <a>Alibaba</a>
                <br> Topic: Low-level vision on video.
                <br/><br/>    
                Dec. 2018 - May. 2019, <b>Research Intern</b>, Algorithm r&d department, <a href="https://www.horizon.ai/">Horizon</a>, Beijing
                <br> Work with: Yongchao Gong, Han Shen, Lichao huang
                <br> Topic: Video object detection.
                <br/><br/>
                Nov. 2017 - May. 2018, <b>Research Intern</b>, IM Group, <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">MicroSoft Research Asia</a>, Beijing
                <br> Work with: Dr. Wenxuan Xie</a>
                <br> Topic: Video object detection/tracking.
            </div>
        </div>
    </div>

    <div style="clear: both;">
        <div class="section">
            <h2>Publications</h2>

            <div class="paper" id="submission">
                <img class="paper" src="material/2019_STCA.PNG" title="Video Object Detection with Spatial-Temporal Context Aggregation" />
                <div> <strong>Video Object Detection with Spatial-Temporal Context Aggregation</strong><br />
                    <strong>Hao Luo</strong>, Lichao Huang, Han Shen, Xinggang Wang<br/>
                    Arxiv 2019. <br/>
                    <a href='https://arxiv.org/abs/1907.04988'>[PDF]</a><a>A new version is to be updated</a>
                </div>
                <div class="spanner"></div>
            </div>
            
            <div class="paper" id="AAAI2019">
                <img class="paper" src="material/aaai2019.png" title="Detect or Track: Towards Cost-Effective Video Object Detection/Tracking" />
                <div> <strong>Detect or Track: Towards Cost-Effective Video Object Detection/Tracking</strong><br />
                    <strong>Hao Luo</strong>, Wenxuan Xie, Xinggang Wang, Wenjun Zeng <br/>
                    The AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), Hawaii, USA, 2019. <br/>
                    <a href='material/2019_AAAI_DorT.pdf'>[PDF]</a><a href='material/2019_AAAI_DorT.jpg'>[Poster]</a> <strong>Spotlight</strong>
                </div>
                <div class="spanner"></div>
            </div>

        </div>
    </div>

    <div style="clear: both;">
        <div class="section">
            <h2>Patents</h2>
            <div class="patent" id="patent">
                2019 | Video object detection with spatial-temporal context aggregation, under review<br>
				2016 | Video framerate up-conversion with convolutional neural network, <a href="material/frc.png"><b>Authorized</b></a><br>
            </div>
        </div>
    </div>
        <div style="clear: both;">
        <div class="section">
		<h2><b>Awards & Honors</b></h2>			
			<div class="hornor">
				2019 | Excellent Graduates of HUST<br>
				2016 | Excellent Graduates of HUST<br>
				2015 | Excellent Student Leader<br>
				2015 | The Second Prize in the Hubei TI Cup Electronic Design Competition<br>
				2013 | Self-improvement scholarship<br>
                    		2016-2019 | The First Prize Scholarship<br>
			</div>
        </div>
    </div>
    
    <div style="clear: both;">
        <p align="right"><font size="5">Last Updated on 17-th Feb., 2020</a></font></p>
        <p align="right"><font size="5">Published with <a href='https://pages.github.com/'>GitHub Pages</a></font></p>
        <p align="right"><font size="5">Modified from <a href="https://github.com/chenxinpeng/chenxinpeng.github.io">Xinpeng Chen</a></font></p>
    </div>
</body>
</html>
